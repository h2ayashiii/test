{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X_array = boston.data\n",
    "y_array = boston.target\n",
    "df = pd.DataFrame(X_array, columns = boston.feature_names).assign(Price=np.array(y_array))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=0000)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=0000)\n",
    "\n",
    "X_train = df_train.drop('Price', axis = 1)\n",
    "y_train = df_train['Price']\n",
    "X_valid = df_valid.drop('Price', axis = 1)\n",
    "y_valid = df_valid['Price']\n",
    "X_test = df_test.drop('Price', axis = 1)\n",
    "y_test = df_test['Price']\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'opt_lgb_model' in locals():\n",
    "    params = opt_lgb_model.params\n",
    "else:\n",
    "    params = {'task': 'train',\n",
    "              'objective': 'regression',\n",
    "              'boosting': 'gbdt',\n",
    "              'metric' : 'rmse',\n",
    "              'verbosity': -1,\n",
    "              'randomseed': 0000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evals_result = {}\n",
    "lgb_model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      valid_sets=[lgb_train, lgb_valid],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      evals_result=evals_result,\n",
    "                      verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show learning loss\n",
    "plt.plot(evals_result['train']['rmse'], label='train')\n",
    "plt.plot(evals_result['valid']['rmse'], label='valid')\n",
    "plt.ylabel('Log loss')\n",
    "plt.xlabel('Boosting round')\n",
    "plt.title('Training performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test)\n",
    "df_pred = pd.concat([y_test.reset_index(drop=True), pd.Series(y_pred)], axis=1)\n",
    "df_pred.columns = ['true', 'pred']\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(df):\n",
    "    MSE = mean_squared_error(df['true'], df['pred'])\n",
    "    RMSE = np.sqrt(mean_squared_error(df['true'], df['pred']))\n",
    "    MAE = mean_absolute_error(df['true'], df['pred'])\n",
    "    R2 = r2_score(df['true'], df['pred'])\n",
    "    eval_result = pd.DataFrame(columns=['MSE', 'RMSE', 'MAE', 'R2'])\n",
    "    eval_result.loc['MLDEL'] = np.round(MSE), np.round(RMSE), np.round(MAE), np.round(R2, decimals=4)\n",
    "\n",
    "    return eval_result\n",
    "\n",
    "eval_result = calc_score(df_pred)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yy_plot(df, idx='R2'):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.plot(df['true'], df['true'], color = 'red', label = 'x=y')\n",
    "    plt.scatter('true', 'pred', data=df)\n",
    "    plt.xlabel('Pred-Y', fontsize=20)\n",
    "    plt.ylabel('True-Y', fontsize=20)\n",
    "    plt.text(5, 50, '{} = {}'.format(idx, eval_result[idx][0]), fontsize=15)\n",
    "\n",
    "yy_plot(df_pred, 'R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgb_model, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(lgb_model, importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as opt_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=0000)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=0000)\n",
    "\n",
    "X_train = df_train.drop('Price', axis = 1)\n",
    "y_train = df_train['Price']\n",
    "X_valid = df_valid.drop('Price', axis = 1)\n",
    "y_valid = df_valid['Price']\n",
    "X_test = df_test.drop('Price', axis = 1)\n",
    "y_test = df_test['Price']\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'verbosity': -1,\n",
    "          'random_seed': 1234}\n",
    "\n",
    "opt_lgb_model = opt_lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              valid_sets=[lgb_train, lgb_valid],\n",
    "                              valid_names=['train', 'valid'],\n",
    "                              num_boost_round=1000,\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose_eval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lgb_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP\n",
    "- [リファレンス](https://shap.readthedocs.io/en/latest/index.html)\n",
    "- [参考](https://blog.amedama.jp/entry/shap-lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values=shap_values,\n",
    "                  features=X_train,\n",
    "                  feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values=shap_values,\n",
    "                  features=X_train,\n",
    "                  feature_names=X_train.columns,\n",
    "                  plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(ind='LSTAT',\n",
    "                     interaction_index='LSTAT',\n",
    "                     shap_values=shap_values,\n",
    "                     features=X_train,\n",
    "                     feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.waterfall_plot(expected_value=explainer.expected_value,\n",
    "                    shap_values=shap_values[0],\n",
    "                    features=X_train.iloc[0],\n",
    "                    feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(base_value=explainer.expected_value,\n",
    "                shap_values=shap_values,\n",
    "                features=X_train,\n",
    "                feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(base_value=explainer.expected_value,\n",
    "                  shap_values=shap_values[:10],\n",
    "                  features=X_train,\n",
    "                  feature_names=list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b573b773d990453b156355dabcc433264ba9ff7e9dd5dd57161c573ec9d57f96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
